{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlbertConfig: (None, <class 'transformers.models.albert.tokenization_albert_fast.AlbertTokenizerFast'>)\n",
      "AlignConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "AriaConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "AyaVisionConfig: (None, <class 'transformers.models.cohere.tokenization_cohere_fast.CohereTokenizerFast'>)\n",
      "BarkConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "BartConfig: (<class 'transformers.models.bart.tokenization_bart.BartTokenizer'>, <class 'transformers.models.bart.tokenization_bart_fast.BartTokenizerFast'>)\n",
      "BertConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "BertGenerationConfig: (None, None)\n",
      "BigBirdConfig: (None, <class 'transformers.models.big_bird.tokenization_big_bird_fast.BigBirdTokenizerFast'>)\n",
      "BigBirdPegasusConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.PegasusTokenizer'>, <class 'transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast'>)\n",
      "BioGptConfig: (<class 'transformers.models.biogpt.tokenization_biogpt.BioGptTokenizer'>, None)\n",
      "BlenderbotConfig: (<class 'transformers.models.blenderbot.tokenization_blenderbot.BlenderbotTokenizer'>, <class 'transformers.models.blenderbot.tokenization_blenderbot_fast.BlenderbotTokenizerFast'>)\n",
      "BlenderbotSmallConfig: (<class 'transformers.models.blenderbot_small.tokenization_blenderbot_small.BlenderbotSmallTokenizer'>, None)\n",
      "BlipConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "Blip2Config: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "BloomConfig: (None, <class 'transformers.models.bloom.tokenization_bloom_fast.BloomTokenizerFast'>)\n",
      "BridgeTowerConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "BrosConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "CamembertConfig: (None, <class 'transformers.models.camembert.tokenization_camembert_fast.CamembertTokenizerFast'>)\n",
      "CanineConfig: (<class 'transformers.models.canine.tokenization_canine.CanineTokenizer'>, None)\n",
      "ChameleonConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "ChineseCLIPConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "ClapConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "CLIPConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "CLIPSegConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "ClvpConfig: (<class 'transformers.models.clvp.tokenization_clvp.ClvpTokenizer'>, None)\n",
      "LlamaConfig: (None, <class 'transformers.models.code_llama.tokenization_code_llama_fast.CodeLlamaTokenizerFast'>)\n",
      "CodeGenConfig: (<class 'transformers.models.codegen.tokenization_codegen.CodeGenTokenizer'>, <class 'transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast'>)\n",
      "CohereConfig: (None, <class 'transformers.models.cohere.tokenization_cohere_fast.CohereTokenizerFast'>)\n",
      "Cohere2Config: (None, <class 'transformers.models.cohere.tokenization_cohere_fast.CohereTokenizerFast'>)\n",
      "ColPaliConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "ConvBertConfig: (<class 'transformers.models.convbert.tokenization_convbert.ConvBertTokenizer'>, <class 'transformers.models.convbert.tokenization_convbert_fast.ConvBertTokenizerFast'>)\n",
      "CpmAntConfig: (<class 'transformers.models.cpmant.tokenization_cpmant.CpmAntTokenizer'>, None)\n",
      "CTRLConfig: (<class 'transformers.models.ctrl.tokenization_ctrl.CTRLTokenizer'>, None)\n",
      "Data2VecAudioConfig: (<class 'transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer'>, None)\n",
      "Data2VecTextConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "DbrxConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "DebertaConfig: (<class 'transformers.models.deberta.tokenization_deberta.DebertaTokenizer'>, <class 'transformers.models.deberta.tokenization_deberta_fast.DebertaTokenizerFast'>)\n",
      "DebertaV2Config: (None, <class 'transformers.models.deberta_v2.tokenization_deberta_v2_fast.DebertaV2TokenizerFast'>)\n",
      "DeepseekV3Config: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "DiffLlamaConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "DistilBertConfig: (<class 'transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer'>, <class 'transformers.models.distilbert.tokenization_distilbert_fast.DistilBertTokenizerFast'>)\n",
      "DPRConfig: (<class 'transformers.models.dpr.tokenization_dpr.DPRQuestionEncoderTokenizer'>, <class 'transformers.models.dpr.tokenization_dpr_fast.DPRQuestionEncoderTokenizerFast'>)\n",
      "ElectraConfig: (<class 'transformers.models.electra.tokenization_electra.ElectraTokenizer'>, <class 'transformers.models.electra.tokenization_electra_fast.ElectraTokenizerFast'>)\n",
      "Emu3Config: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "ErnieConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "ErnieMConfig: (None, None)\n",
      "EsmConfig: (<class 'transformers.models.esm.tokenization_esm.EsmTokenizer'>, None)\n",
      "FalconConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "FalconMambaConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "FastSpeech2ConformerConfig: (None, None)\n",
      "FlaubertConfig: (<class 'transformers.models.flaubert.tokenization_flaubert.FlaubertTokenizer'>, None)\n",
      "FNetConfig: (<class 'transformers.models.fnet.tokenization_fnet.FNetTokenizer'>, <class 'transformers.models.fnet.tokenization_fnet_fast.FNetTokenizerFast'>)\n",
      "FSMTConfig: (<class 'transformers.models.fsmt.tokenization_fsmt.FSMTTokenizer'>, None)\n",
      "FunnelConfig: (<class 'transformers.models.funnel.tokenization_funnel.FunnelTokenizer'>, <class 'transformers.models.funnel.tokenization_funnel_fast.FunnelTokenizerFast'>)\n",
      "GemmaConfig: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "Gemma2Config: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "Gemma3Config: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "Gemma3TextConfig: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "GitConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "GlmConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "Glm4Config: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "GPT2Config: (None, None)\n",
      "GPT2Config: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "GPTBigCodeConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "GPTNeoConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "GPTNeoXConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "GPTNeoXJapaneseConfig: (<class 'transformers.models.gpt_neox_japanese.tokenization_gpt_neox_japanese.GPTNeoXJapaneseTokenizer'>, None)\n",
      "GPTJConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "GPTSanJapaneseConfig: (<class 'transformers.models.deprecated.gptsan_japanese.tokenization_gptsan_japanese.GPTSanJapaneseTokenizer'>, None)\n",
      "GroundingDinoConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "GroupViTConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "HeliumConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "HubertConfig: (<class 'transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer'>, None)\n",
      "IBertConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "IdeficsConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "Idefics2Config: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "Idefics3Config: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "InstructBlipConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "InstructBlipVideoConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "JambaConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "JetMoeConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "JukeboxConfig: (<class 'transformers.models.deprecated.jukebox.tokenization_jukebox.JukeboxTokenizer'>, None)\n",
      "Kosmos2Config: (None, <class 'transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast'>)\n",
      "LayoutLMConfig: (<class 'transformers.models.layoutlm.tokenization_layoutlm.LayoutLMTokenizer'>, <class 'transformers.models.layoutlm.tokenization_layoutlm_fast.LayoutLMTokenizerFast'>)\n",
      "LayoutLMv2Config: (<class 'transformers.models.layoutlmv2.tokenization_layoutlmv2.LayoutLMv2Tokenizer'>, <class 'transformers.models.layoutlmv2.tokenization_layoutlmv2_fast.LayoutLMv2TokenizerFast'>)\n",
      "LayoutLMv3Config: (<class 'transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer'>, <class 'transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast'>)\n",
      "LEDConfig: (<class 'transformers.models.led.tokenization_led.LEDTokenizer'>, <class 'transformers.models.led.tokenization_led_fast.LEDTokenizerFast'>)\n",
      "LiltConfig: (<class 'transformers.models.layoutlmv3.tokenization_layoutlmv3.LayoutLMv3Tokenizer'>, <class 'transformers.models.layoutlmv3.tokenization_layoutlmv3_fast.LayoutLMv3TokenizerFast'>)\n",
      "LlamaConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "Llama4Config: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "Llama4TextConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "LlavaConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "LlavaNextConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "LlavaNextVideoConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "LlavaOnevisionConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "LongformerConfig: (<class 'transformers.models.longformer.tokenization_longformer.LongformerTokenizer'>, <class 'transformers.models.longformer.tokenization_longformer_fast.LongformerTokenizerFast'>)\n",
      "LongT5Config: (None, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "LukeConfig: (<class 'transformers.models.luke.tokenization_luke.LukeTokenizer'>, None)\n",
      "LxmertConfig: (<class 'transformers.models.lxmert.tokenization_lxmert.LxmertTokenizer'>, <class 'transformers.models.lxmert.tokenization_lxmert_fast.LxmertTokenizerFast'>)\n",
      "M2M100Config: (None, None)\n",
      "MambaConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "Mamba2Config: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "MarianConfig: (None, None)\n",
      "MBartConfig: (None, <class 'transformers.models.mbart.tokenization_mbart_fast.MBartTokenizerFast'>)\n",
      "MegaConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "MegatronBertConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "MgpstrConfig: (<class 'transformers.models.mgp_str.tokenization_mgp_str.MgpstrTokenizer'>, None)\n",
      "MistralConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "MixtralConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "MllamaConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "MobileBertConfig: (<class 'transformers.models.mobilebert.tokenization_mobilebert.MobileBertTokenizer'>, <class 'transformers.models.mobilebert.tokenization_mobilebert_fast.MobileBertTokenizerFast'>)\n",
      "ModernBertConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "MoonshineConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "MoshiConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "MPNetConfig: (<class 'transformers.models.mpnet.tokenization_mpnet.MPNetTokenizer'>, <class 'transformers.models.mpnet.tokenization_mpnet_fast.MPNetTokenizerFast'>)\n",
      "MptConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "MraConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "MT5Config: (None, <class 'transformers.models.mt5.tokenization_mt5_fast.MT5TokenizerFast'>)\n",
      "MusicgenConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.T5Tokenizer'>, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "MusicgenMelodyConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.T5Tokenizer'>, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "MvpConfig: (<class 'transformers.models.mvp.tokenization_mvp.MvpTokenizer'>, <class 'transformers.models.mvp.tokenization_mvp_fast.MvpTokenizerFast'>)\n",
      "NemotronConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "NezhaConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "NllbMoeConfig: (None, <class 'transformers.models.nllb.tokenization_nllb_fast.NllbTokenizerFast'>)\n",
      "NystromformerConfig: (None, <class 'transformers.models.albert.tokenization_albert_fast.AlbertTokenizerFast'>)\n",
      "OlmoConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "Olmo2Config: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "OlmoeConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "OmDetTurboConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "OneFormerConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "OpenAIGPTConfig: (<class 'transformers.models.openai.tokenization_openai.OpenAIGPTTokenizer'>, <class 'transformers.models.openai.tokenization_openai_fast.OpenAIGPTTokenizerFast'>)\n",
      "OPTConfig: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "Owlv2Config: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "OwlViTConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "PaliGemmaConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "PegasusConfig: (None, <class 'transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast'>)\n",
      "PegasusXConfig: (None, <class 'transformers.models.pegasus.tokenization_pegasus_fast.PegasusTokenizerFast'>)\n",
      "PerceiverConfig: (<class 'transformers.models.perceiver.tokenization_perceiver.PerceiverTokenizer'>, None)\n",
      "PersimmonConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "PhiConfig: (<class 'transformers.models.codegen.tokenization_codegen.CodeGenTokenizer'>, <class 'transformers.models.codegen.tokenization_codegen_fast.CodeGenTokenizerFast'>)\n",
      "Phi3Config: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "PhimoeConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "Pix2StructConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.T5Tokenizer'>, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "PixtralVisionConfig: (None, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>)\n",
      "PLBartConfig: (None, None)\n",
      "ProphetNetConfig: (<class 'transformers.models.prophetnet.tokenization_prophetnet.ProphetNetTokenizer'>, None)\n",
      "QDQBertConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "Qwen2Config: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "Qwen2_5_VLConfig: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "Qwen2AudioConfig: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "Qwen2MoeConfig: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "Qwen2VLConfig: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "Qwen3Config: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "Qwen3MoeConfig: (<class 'transformers.models.qwen2.tokenization_qwen2.Qwen2Tokenizer'>, <class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'>)\n",
      "RagConfig: (<class 'transformers.models.rag.tokenization_rag.RagTokenizer'>, None)\n",
      "RealmConfig: (<class 'transformers.models.deprecated.realm.tokenization_realm.RealmTokenizer'>, <class 'transformers.models.deprecated.realm.tokenization_realm_fast.RealmTokenizerFast'>)\n",
      "RecurrentGemmaConfig: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "ReformerConfig: (None, <class 'transformers.models.reformer.tokenization_reformer_fast.ReformerTokenizerFast'>)\n",
      "RemBertConfig: (None, <class 'transformers.models.rembert.tokenization_rembert_fast.RemBertTokenizerFast'>)\n",
      "RetriBertConfig: (<class 'transformers.models.deprecated.retribert.tokenization_retribert.RetriBertTokenizer'>, <class 'transformers.models.deprecated.retribert.tokenization_retribert_fast.RetriBertTokenizerFast'>)\n",
      "RobertaConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "RobertaPreLayerNormConfig: (<class 'transformers.models.roberta.tokenization_roberta.RobertaTokenizer'>, <class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>)\n",
      "RoCBertConfig: (<class 'transformers.models.roc_bert.tokenization_roc_bert.RoCBertTokenizer'>, None)\n",
      "RoFormerConfig: (<class 'transformers.models.roformer.tokenization_roformer.RoFormerTokenizer'>, <class 'transformers.models.roformer.tokenization_roformer_fast.RoFormerTokenizerFast'>)\n",
      "RwkvConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "SeamlessM4TConfig: (None, <class 'transformers.models.seamless_m4t.tokenization_seamless_m4t_fast.SeamlessM4TTokenizerFast'>)\n",
      "SeamlessM4Tv2Config: (None, <class 'transformers.models.seamless_m4t.tokenization_seamless_m4t_fast.SeamlessM4TTokenizerFast'>)\n",
      "ShieldGemma2Config: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "SiglipConfig: (None, None)\n",
      "Siglip2Config: (None, <class 'transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast'>)\n",
      "Speech2TextConfig: (None, None)\n",
      "Speech2Text2Config: (<class 'transformers.models.deprecated.speech_to_text_2.tokenization_speech_to_text_2.Speech2Text2Tokenizer'>, None)\n",
      "SpeechT5Config: (None, None)\n",
      "SplinterConfig: (<class 'transformers.models.splinter.tokenization_splinter.SplinterTokenizer'>, <class 'transformers.models.splinter.tokenization_splinter_fast.SplinterTokenizerFast'>)\n",
      "SqueezeBertConfig: (<class 'transformers.models.squeezebert.tokenization_squeezebert.SqueezeBertTokenizer'>, <class 'transformers.models.squeezebert.tokenization_squeezebert_fast.SqueezeBertTokenizerFast'>)\n",
      "StableLmConfig: (None, <class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>)\n",
      "Starcoder2Config: (<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>, <class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>)\n",
      "SwitchTransformersConfig: (None, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "T5Config: (None, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "TapasConfig: (<class 'transformers.models.tapas.tokenization_tapas.TapasTokenizer'>, None)\n",
      "TransfoXLConfig: (<class 'transformers.models.deprecated.transfo_xl.tokenization_transfo_xl.TransfoXLTokenizer'>, None)\n",
      "TvpConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "UdopConfig: (None, <class 'transformers.models.udop.tokenization_udop_fast.UdopTokenizerFast'>)\n",
      "UMT5Config: (None, <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>)\n",
      "VideoLlavaConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "ViltConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "VipLlavaConfig: (<class 'transformers.utils.dummy_sentencepiece_objects.LlamaTokenizer'>, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "VisualBertConfig: (<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>, <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>)\n",
      "VitsConfig: (<class 'transformers.models.vits.tokenization_vits.VitsTokenizer'>, None)\n",
      "Wav2Vec2Config: (<class 'transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer'>, None)\n",
      "Wav2Vec2BertConfig: (<class 'transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer'>, None)\n",
      "Wav2Vec2ConformerConfig: (<class 'transformers.models.wav2vec2.tokenization_wav2vec2.Wav2Vec2CTCTokenizer'>, None)\n",
      "WhisperConfig: (<class 'transformers.models.whisper.tokenization_whisper.WhisperTokenizer'>, <class 'transformers.models.whisper.tokenization_whisper_fast.WhisperTokenizerFast'>)\n",
      "XCLIPConfig: (<class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>, <class 'transformers.models.clip.tokenization_clip_fast.CLIPTokenizerFast'>)\n",
      "XGLMConfig: (None, <class 'transformers.models.xglm.tokenization_xglm_fast.XGLMTokenizerFast'>)\n",
      "XLMConfig: (<class 'transformers.models.xlm.tokenization_xlm.XLMTokenizer'>, None)\n",
      "XLMProphetNetConfig: (None, None)\n",
      "XLMRobertaConfig: (None, <class 'transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast'>)\n",
      "XLMRobertaXLConfig: (None, <class 'transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast'>)\n",
      "XLNetConfig: (None, <class 'transformers.models.xlnet.tokenization_xlnet_fast.XLNetTokenizerFast'>)\n",
      "XmodConfig: (None, <class 'transformers.models.xlm_roberta.tokenization_xlm_roberta_fast.XLMRobertaTokenizerFast'>)\n",
      "YosoConfig: (None, <class 'transformers.models.albert.tokenization_albert_fast.AlbertTokenizerFast'>)\n",
      "ZambaConfig: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n",
      "Zamba2Config: (None, <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers.models.auto.tokenization_auto import TOKENIZER_MAPPING\n",
    "\n",
    "# æŸ¥çœ‹æ‰€æœ‰æ³¨å†Œçš„åˆ†è¯å™¨æ˜ å°„\n",
    "for model_config, tokenizer_class in TOKENIZER_MAPPING.items():\n",
    "    print(f\"{model_config.__name__}: {tokenizer_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹ç”Ÿæˆ 1000 ä¸ªé—®é¢˜...\n",
      "éš¾åº¦: easy\n",
      "æ–‡ä»¶å: GSM_data_easy_1000.jsonl\n",
      "éªŒè¯: å½“å‰è¿è¡Œæ—¶æ¨¡å¼ USE_MOD = False\n",
      "------------------------------\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 1000/1000 ä¸ªé—®é¢˜...\n",
      "\n",
      "æˆåŠŸå®Œæˆ: GSM_data_easy_1000.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "def set_global_mod_mode(use_mod: bool):\n",
    "    \"\"\"\n",
    "    ç›´æ¥è¯»å–ã€ä¿®æ”¹å¹¶é‡å†™ const/params.py æ–‡ä»¶æ¥è®¾ç½®å…¨å±€æ¨¡å¼ã€‚\n",
    "    \"\"\"\n",
    "    params_path = os.path.join('const', 'params.py')\n",
    "    \n",
    "    try:\n",
    "        with open(params_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"é”™è¯¯: æ— æ³•æ‰¾åˆ° '{params_path}'ã€‚è¯·ç¡®ä¿è„šæœ¬åœ¨ iGSM é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œã€‚\")\n",
    "        exit(1)\n",
    "\n",
    "    found_line = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.match(r'^\\s*USE_MOD\\s*=', line):\n",
    "            lines[i] = f\"USE_MOD = {use_mod}\\n\"\n",
    "            found_line = True\n",
    "            break\n",
    "            \n",
    "    if not found_line:\n",
    "        lines.append(f\"\\nUSE_MOD = {use_mod}\\n\")\n",
    "\n",
    "    with open(params_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "def run_generation(num_problems, difficulty, output_file, seed=42, batch_size=1000):\n",
    "    \"\"\"\n",
    "    å°è£…äº†å¯¼å…¥å’Œç”Ÿæˆé€»è¾‘çš„ä¸»å‡½æ•°ã€‚\n",
    "    \"\"\"\n",
    "    from data_gen.pretrain.id_gen import IdGen\n",
    "    from tools.tools import tokenizer, fix_seed\n",
    "    from const import params\n",
    "\n",
    "    # fix_seed(seed)\n",
    "    data_buffer, total_generated = [], 0\n",
    "\n",
    "    print(f\"å¼€å§‹ç”Ÿæˆ {num_problems} ä¸ªé—®é¢˜...\")\n",
    "    print(f\"éš¾åº¦: {difficulty}\")\n",
    "    print(f\"æ–‡ä»¶å: {output_file}\")\n",
    "    print(f\"éªŒè¯: å½“å‰è¿è¡Œæ—¶æ¨¡å¼ USE_MOD = {params.USE_MOD}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # vvvvvvvv å…³é”®ä¿®æ­£ç‚¹ vvvvvvvv\n",
    "        # vvvvvvvv å…³é”®ä¿®æ­£ç‚¹ vvvvvvvv\n",
    "    def get_prob_sol_ans_triple(tpy: Literal[\"easy\", \"med\", \"hard\"]):\n",
    "        assert tpy in [\"easy\", \"med\", \"hard\"], \"Invalid type: Choose 'easy', 'med' or 'hard'\"\n",
    "        \n",
    "        if tpy == \"easy\":\n",
    "            max_op, max_edge = (9, 12)\n",
    "        elif tpy == \"med\":\n",
    "            max_op, max_edge = (15, 20)\n",
    "        else:  # hard\n",
    "            max_op, max_edge = (21, 28)\n",
    "\n",
    "        id_gen = IdGen(max_op=max_op, max_edge=max_edge, perm_level=5, detail_level=0)\n",
    "        \n",
    "        # æ ¹æ®å½“å‰æ¨¡å¼å†³å®šä¼ é€’ç»™ gen_prob çš„å“ˆå¸Œåˆ—è¡¨\n",
    "        if params.USE_MOD:\n",
    "            valid_hashes = list(range(23))  # å–æ¨¡æ¨¡å¼\n",
    "        else:\n",
    "            valid_hashes = [0]  # éå–æ¨¡æ¨¡å¼\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                id_gen.gen_prob(valid_hashes, p_format=\"pq\")\n",
    "                break \n",
    "            except Exception:\n",
    "                continue\n",
    "        return id_gen\n",
    "    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        for i in range(num_problems):\n",
    "            id_gen = get_prob_sol_ans_triple(difficulty)\n",
    "            problem_text = tokenizer.decode(id_gen.prob_token, skip_special_tokens=True).strip()\n",
    "            solution_text = tokenizer.decode(id_gen.sol_token, skip_special_tokens=True).strip()\n",
    "            answer_text = tokenizer.decode(id_gen.ans_token, skip_special_tokens=True).strip()\n",
    "            \n",
    "            data_buffer.append({\n",
    "                \"id\": f\"{difficulty}_{seed}_{i}\",\n",
    "                \"problem\": problem_text, \"solution\": solution_text, \"answer\": answer_text\n",
    "            })\n",
    "            \n",
    "            if len(data_buffer) >= batch_size or (i + 1) == num_problems:\n",
    "                for item in data_buffer:\n",
    "                    f_out.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "                total_generated += len(data_buffer)\n",
    "                print(f\"å·²ç”Ÿæˆå¹¶ä¿å­˜ {total_generated}/{num_problems} ä¸ªé—®é¢˜...\")\n",
    "                data_buffer = []\n",
    "            \n",
    "    print(f\"\\næˆåŠŸå®Œæˆ: {output_file}\")\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "#                      ä¸»ç¨‹åºå…¥å£\n",
    "# ===================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- æ‰€æœ‰å¯è°ƒå‚æ•°éƒ½é›†ä¸­åœ¨è¿™é‡Œ ---\n",
    "    USE_MOD = False\n",
    "    NUM_TO_GENERATE = 1000\n",
    "    DIFFICULTY = \"easy\"\n",
    "    OUTPUT_FILE = \"GSM_data_easy_1000.jsonl\"\n",
    "    BATCH_SIZE = 1000\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    # --- æ‰§è¡Œ ---\n",
    "    set_global_mod_mode(USE_MOD)\n",
    "    run_generation(\n",
    "        num_problems=NUM_TO_GENERATE,\n",
    "        difficulty=DIFFICULTY,\n",
    "        output_file=OUTPUT_FILE,\n",
    "        seed=RANDOM_SEED,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ˜ºğŸ¤–ç›´å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹ç”Ÿæˆ 1000000 ä¸ªé—®é¢˜...\n",
      "éš¾åº¦: easy\n",
      "æ–‡ä»¶å: GSM_data_easy_10000002.jsonl\n",
      "éªŒè¯: å½“å‰è¿è¡Œæ—¶æ¨¡å¼ USE_MOD = False\n",
      "------------------------------\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 10000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 20000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 30000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 40000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 50000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 60000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 70000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 80000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 90000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 100000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 110000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 120000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 130000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 140000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 150000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 160000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 170000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 180000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 190000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 200000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 210000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 220000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 230000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 240000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 250000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 260000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 270000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 280000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 290000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 300000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 310000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 320000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 330000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 340000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 350000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 360000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 370000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 380000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 390000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 400000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 410000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 420000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 430000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 440000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 450000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 460000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 470000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 480000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 490000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 500000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 510000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 520000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 530000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 540000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 550000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 560000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 570000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 580000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 590000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 600000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 610000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 620000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 630000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 640000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 650000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 660000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 670000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 680000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 690000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 700000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 710000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 720000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 730000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 740000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 750000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 760000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 770000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 780000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 790000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 800000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 810000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 820000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 830000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 840000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 850000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 860000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 870000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 880000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 890000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 900000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 910000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 920000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 930000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 940000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 950000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 960000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 970000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 980000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 990000/1000000 ä¸ªé—®é¢˜...\n",
      "å·²ç”Ÿæˆå¹¶ä¿å­˜ 1000000/1000000 ä¸ªé—®é¢˜...\n",
      "\n",
      "æˆåŠŸå®Œæˆ: GSM_data_easy_10000002.jsonl\n",
      "[*] å¼€å§‹è½¬æ¢æ–‡ä»¶...\n",
      "    è¾“å…¥: GSM_data_easy_10000002.jsonl\n",
      "    è¾“å‡º: GSM_data_easy_1000000_ğŸ˜ºğŸ¤–2.jsonl\n",
      "è½¬æ¢ä¸­: |          | 1000000/? [00:15<00:00]\n",
      "\n",
      "==============================\n",
      " è½¬æ¢å®Œæˆ \n",
      "==============================\n",
      "[*] å…±å¤„ç†è¾“å…¥æ–‡ä»¶è¡Œæ•°: 1,000,000\n",
      "[*] æˆåŠŸè½¬æ¢å¹¶å†™å…¥è¡Œæ•°: 1,000,000\n",
      "[*] è·³è¿‡æˆ–è½¬æ¢å¤±è´¥è¡Œæ•°: 0\n",
      "[*] ç»“æœå·²ä¿å­˜è‡³: GSM_data_easy_1000000_ğŸ˜ºğŸ¤–2.jsonl\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from typing import Literal\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================\n",
    "#                   æ•°æ®ç”Ÿæˆéƒ¨åˆ†\n",
    "# ==============================================================\n",
    "\n",
    "def set_global_mod_mode(use_mod: bool):\n",
    "    \"\"\"\n",
    "    ç›´æ¥è¯»å–ã€ä¿®æ”¹å¹¶é‡å†™ const/params.py æ–‡ä»¶æ¥è®¾ç½®å…¨å±€æ¨¡å¼ã€‚\n",
    "    \"\"\"\n",
    "    params_path = os.path.join('const', 'params.py')\n",
    "    \n",
    "    try:\n",
    "        with open(params_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"é”™è¯¯: æ— æ³•æ‰¾åˆ° '{params_path}'ã€‚è¯·ç¡®ä¿è„šæœ¬åœ¨ iGSM é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œã€‚\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    found_line = False\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.match(r'^\\s*USE_MOD\\s*=', line):\n",
    "            lines[i] = f\"USE_MOD = {use_mod}\\n\"\n",
    "            found_line = True\n",
    "            break\n",
    "            \n",
    "    if not found_line:\n",
    "        lines.append(f\"\\nUSE_MOD = {use_mod}\\n\")\n",
    "\n",
    "    with open(params_path, 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "\n",
    "def run_generation(num_problems, difficulty, output_file, seed=42, batch_size=1000):\n",
    "    \"\"\"\n",
    "    å°è£…äº†å¯¼å…¥å’Œç”Ÿæˆé€»è¾‘çš„ä¸»å‡½æ•°ã€‚\n",
    "    \"\"\"\n",
    "    from data_gen.pretrain.id_gen import IdGen\n",
    "    from tools.tools import tokenizer\n",
    "    from const import params\n",
    "\n",
    "    data_buffer, total_generated = [], 0\n",
    "\n",
    "    print(f\"å¼€å§‹ç”Ÿæˆ {num_problems} ä¸ªé—®é¢˜...\")\n",
    "    print(f\"éš¾åº¦: {difficulty}\")\n",
    "    print(f\"æ–‡ä»¶å: {output_file}\")\n",
    "    print(f\"éªŒè¯: å½“å‰è¿è¡Œæ—¶æ¨¡å¼ USE_MOD = {params.USE_MOD}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # vvvvvvvv æ”¯æŒ easy/med/hard vvvvvvvv\n",
    "    def get_prob_sol_ans_triple(tpy: Literal[\"easy\", \"med\", \"hard\"]):\n",
    "        assert tpy in [\"veasy\",\"easy\", \"med\", \"hard\"], \"Invalid type: Choose  'veasy','easy', 'med' or 'hard'\"\n",
    "        \n",
    "        if tpy == \"veasy\":\n",
    "            max_op, max_edge = (5, 8)\n",
    "        elif tpy == \"easy\":\n",
    "            max_op, max_edge = (9, 12)\n",
    "        elif tpy == \"med\":\n",
    "            max_op, max_edge = (15, 20)\n",
    "        else:  # hard\n",
    "            max_op, max_edge = (21, 28)\n",
    "\n",
    "        id_gen = IdGen(max_op=max_op, max_edge=max_edge, perm_level=5, detail_level=0)\n",
    "        \n",
    "        # æ ¹æ®å½“å‰æ¨¡å¼å†³å®šä¼ é€’ç»™ gen_prob çš„å“ˆå¸Œåˆ—è¡¨\n",
    "        valid_hashes = list(range(23)) if params.USE_MOD else [0]\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                id_gen.gen_prob(valid_hashes, p_format=\"pq\")\n",
    "                break \n",
    "            except Exception:\n",
    "                continue\n",
    "        return id_gen\n",
    "    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        for i in range(num_problems):\n",
    "            id_gen = get_prob_sol_ans_triple(difficulty)\n",
    "            problem_text = tokenizer.decode(id_gen.prob_token, skip_special_tokens=True).strip()\n",
    "            solution_text = tokenizer.decode(id_gen.sol_token, skip_special_tokens=True).strip()\n",
    "            answer_text = tokenizer.decode(id_gen.ans_token, skip_special_tokens=True).strip()\n",
    "            \n",
    "            data_buffer.append({\n",
    "                \"id\": f\"{difficulty}_{seed}_{i}\",\n",
    "                \"problem\": problem_text, \"solution\": solution_text, \"answer\": answer_text\n",
    "            })\n",
    "            \n",
    "            if len(data_buffer) >= batch_size or (i + 1) == num_problems:\n",
    "                for item in data_buffer:\n",
    "                    f_out.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "                total_generated += len(data_buffer)\n",
    "                print(f\"å·²ç”Ÿæˆå¹¶ä¿å­˜ {total_generated}/{num_problems} ä¸ªé—®é¢˜...\")\n",
    "                data_buffer = []\n",
    "            \n",
    "    print(f\"\\næˆåŠŸå®Œæˆ: {output_file}\")\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#                   è½¬æ¢ä¸º ğŸ˜ºğŸ¤– å¯¹è¯æ ¼å¼\n",
    "# ==============================================================\n",
    "\n",
    "def convert_to_conversation(data: dict) -> list | None:\n",
    "    \"\"\"\n",
    "    å°†å•è¡ŒåŸå§‹JSONå¯¹è±¡è½¬æ¢ä¸ºç›®æ ‡å¯¹è¯æ ¼å¼ [{\"ğŸ˜º\": ...}, {\"ğŸ¤–\": ...}]ã€‚\n",
    "    \"\"\"\n",
    "    problem_text = data.get(\"problem\")\n",
    "    solution_text = data.get(\"solution\")\n",
    "    answer_text = data.get(\"answer\")\n",
    "\n",
    "    if not all([problem_text, solution_text, answer_text]):\n",
    "        return None\n",
    "\n",
    "    assistant_content = solution_text.strip() + \"\\n\" + answer_text.strip()\n",
    "    conversation = [\n",
    "        {\"ğŸ˜º\": problem_text.strip()},\n",
    "        {\"ğŸ¤–\": assistant_content}\n",
    "    ]\n",
    "    return conversation\n",
    "\n",
    "\n",
    "def convert_file(input_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    å°†ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"[*] å¼€å§‹è½¬æ¢æ–‡ä»¶...\")\n",
    "    print(f\"    è¾“å…¥: {input_file}\")\n",
    "    print(f\"    è¾“å‡º: {output_file}\")\n",
    "\n",
    "    lines_processed = 0\n",
    "    lines_converted = 0\n",
    "    lines_skipped = 0\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f_in, \\\n",
    "             open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "            \n",
    "            pbar = tqdm(f_in, desc=\"è½¬æ¢ä¸­\", unit=\"è¡Œ\", file=sys.stdout, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]')\n",
    "\n",
    "            for line in pbar:\n",
    "                lines_processed += 1\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    lines_skipped += 1\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    original_data = json.loads(line)\n",
    "                    converted_conversation = convert_to_conversation(original_data)\n",
    "\n",
    "                    if converted_conversation:\n",
    "                        output_line = json.dumps(\n",
    "                            converted_conversation, \n",
    "                            ensure_ascii=False, \n",
    "                            separators=(',', ':')\n",
    "                        )\n",
    "                        f_out.write(output_line + '\\n')\n",
    "                        lines_converted += 1\n",
    "                    else:\n",
    "                        lines_skipped += 1\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"\\n[!] è­¦å‘Š: ç¬¬ {lines_processed} è¡Œ JSON è§£æå¤±è´¥ï¼Œå·²è·³è¿‡ã€‚\", file=sys.stderr)\n",
    "                    lines_skipped += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n[!] é”™è¯¯: å¤„ç†ç¬¬ {lines_processed} è¡Œæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\", file=sys.stderr)\n",
    "                    lines_skipped += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n[X] é”™è¯¯: è¾“å…¥æ–‡ä»¶ '{input_file}' æœªæ‰¾åˆ°ã€‚\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\" è½¬æ¢å®Œæˆ \")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"[*] å…±å¤„ç†è¾“å…¥æ–‡ä»¶è¡Œæ•°: {lines_processed:,}\")\n",
    "    print(f\"[*] æˆåŠŸè½¬æ¢å¹¶å†™å…¥è¡Œæ•°: {lines_converted:,}\")\n",
    "    print(f\"[*] è·³è¿‡æˆ–è½¬æ¢å¤±è´¥è¡Œæ•°: {lines_skipped:,}\")\n",
    "    print(f\"[*] ç»“æœå·²ä¿å­˜è‡³: {output_file}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "#                      ä¸»ç¨‹åºå…¥å£\n",
    "# ==============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- ç”Ÿæˆå‚æ•° ---\n",
    "    USE_MOD = False\n",
    "    NUM_TO_GENERATE = 1000000\n",
    "    DIFFICULTY = \"easy\"   # å¯é€‰: \"veasy\" | \"easy\" | \"med\" | \"hard\"\n",
    "    GEN_OUTPUT_FILE = f\"GSM_data_{DIFFICULTY}_{NUM_TO_GENERATE}2.jsonl\"\n",
    "    RANDOM_SEED = 42\n",
    "\n",
    "    # --- è½¬æ¢å‚æ•° ---\n",
    "    FINAL_OUTPUT_FILE = f\"GSM_data_{DIFFICULTY}_{NUM_TO_GENERATE}_ğŸ˜ºğŸ¤–2.jsonl\"\n",
    "\n",
    "    # --- æ‰§è¡Œæ•°æ®ç”Ÿæˆ ---\n",
    "    set_global_mod_mode(USE_MOD)\n",
    "    run_generation(\n",
    "        num_problems=NUM_TO_GENERATE,\n",
    "        difficulty=DIFFICULTY,\n",
    "        output_file=GEN_OUTPUT_FILE,\n",
    "        seed=RANDOM_SEED,\n",
    "        batch_size=10000\n",
    "    )\n",
    "\n",
    "    # --- æ‰§è¡Œæ–‡ä»¶è½¬æ¢ ---\n",
    "    convert_file(GEN_OUTPUT_FILE, FINAL_OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSM_data_veasy__1000_ğŸ˜ºğŸ¤–.jsonl : 650.41\n",
      "GSM_data_easy__1000_ğŸ˜ºğŸ¤–.jsonl : 902.75\n",
      "GSM_data_med_500000_ğŸ˜ºğŸ¤–.jsonl : 1258.97\n",
      "GSM_data_hard_500000_ğŸ˜ºğŸ¤–.jsonl : 1556.80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def avg_line_length(file_path, max_lines=1000):\n",
    "    total_len = 0\n",
    "    count = 0\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= max_lines:\n",
    "                break\n",
    "            total_len += len(line.strip())\n",
    "            count += 1\n",
    "    return total_len / count if count > 0 else 0\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    for fname in os.listdir(\".\"):\n",
    "        if \"ğŸ˜ºğŸ¤–\" in fname and fname.endswith(\".jsonl\"):\n",
    "            avg_len = avg_line_length(fname, max_lines=1000)\n",
    "            results.append((fname, avg_len))\n",
    "    \n",
    "    # æ’åºï¼ˆä»çŸ­åˆ°é•¿ï¼‰\n",
    "    results.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for fname, avg_len in results:\n",
    "        print(f\"{fname} : {avg_len:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
